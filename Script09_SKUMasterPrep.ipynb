{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "177fdff8-4788-4138-a0e9-bd14055835aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Dependencies\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import PatternFill, Border, Side, Font\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.worksheet.table import Table, TableStyleInfo\n",
    "from openpyxl.styles.alignment import Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb023bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "demand_filepath = \"28-04-2024_Demand_Automation.xlsx\"\n",
    "\n",
    "NFC_master_file = os.path.join(cwd, \"client_data\", \"AMF_Inventory_Item_Master___Al_050224.xlsx\")\n",
    "KFC_master_file = os.path.join(cwd, \"client_data\", \"Master file on 11-02-2024.xlsx\")\n",
    "GFC_master_file = os.path.join(cwd, \"client_data\", \"AMF_Inventory_Item_Master___Al_080224.xlsx\")\n",
    "budget_file = os.path.join(cwd, \"client_data\", \"PROTEIN_COGS_FORECAST-Q4+2024_BUDGET-TP3_V16.01.xlsx\")\n",
    "\n",
    "trimming_output = \"29-04-24_Trimming_Output.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8974ceb-f3df-4b7b-9f26-c19dc6806e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# df_bom = pd.read_excel(\"BOM Top 80 Output.xlsx\", skiprows=1)  # Row 5 in Excel\n",
    "\n",
    "\n",
    "# df_bom.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4744eac5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DataFrames are written to 03-05-2024 RMSKU Master List.xlsx\n"
     ]
    }
   ],
   "source": [
    "#####RMSKU Master List Input\n",
    "df_bom= pd.read_excel(r\"BOM Top 80 Output.xlsx\",skiprows=1)\n",
    "df_bom = df_bom.drop(df_bom.columns[0], axis=1)\n",
    "df_rm= pd.read_excel(r\"RM Supply.xlsx\",skiprows=1)\n",
    "df_rm = df_rm.drop(df_rm.columns[0], axis=1)\n",
    "\n",
    "#Taking all unique combination of RMCode , FactCode and RM UOM from RM Supply\n",
    "df_rm_unique = df_rm[['RM Code', 'RM UOM', 'FactCode']].drop_duplicates()\n",
    "#Taking all unique combination of RMCode and RM Description UOM from Top 80% BOM\n",
    "df_bom_unique= df_bom[['RM CODE','RM DESC']].drop_duplicates()\n",
    "df_bom_unique.columns= ['RM Code','RM Desc']\n",
    "\n",
    "#Merging both datasets\n",
    "df_merge= pd.merge( df_rm_unique,df_bom_unique, on='RM Code', how= 'left')\n",
    "\n",
    "dataframes = {\n",
    "    'RMSKU Master': df_merge,\n",
    "   }\n",
    "\n",
    "# Specify the path to save your Excel file\n",
    "file_path = r'03-05-2024 RMSKU Master List.xlsx'\n",
    "# Using ExcelWriter to write each DataFrame to a separate sheet\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    for sheet_name, dataframe in dataframes.items():\n",
    "        dataframe.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    # Load the workbook and apply formatting\n",
    "    workbook = writer.book\n",
    "    for sheet_name in dataframes.keys():\n",
    "        worksheet = workbook[sheet_name]\n",
    "        worksheet.sheet_view.showGridLines = False  # Remove gridlines\n",
    "\n",
    "        # Add one row and column at the top\n",
    "        worksheet.insert_rows(1)\n",
    "        worksheet.insert_cols(1)\n",
    "        worksheet.cell(row=1, column=1)\n",
    "\n",
    "        # Add table borders\n",
    "        border = Border(left=Side(style='thin'), \n",
    "                        right=Side(style='thin'), \n",
    "                        top=Side(style='thin'), \n",
    "                        bottom=Side(style='thin'))\n",
    "        for row in worksheet.iter_rows(min_row=2, min_col=2, max_col=worksheet.max_column):\n",
    "            for cell in row:\n",
    "                cell.border = border\n",
    "\n",
    "        \n",
    "# Set light blue color for headers\n",
    "        for cell in worksheet.iter_cols(min_row=2, min_col=2):\n",
    "            cell[0].fill = PatternFill(start_color=\"ADD8E6\", end_color=\"ADD8E6\", fill_type=\"solid\")  # Light blue\n",
    "    \n",
    "        # Remove borders for the extra added row and column at the top\n",
    "        for cell in worksheet['A1:C1'][0]:\n",
    "            cell.border = None\n",
    "# Autofit columns\n",
    "        for col in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column = col[0].column_letter  # Get the column name\n",
    "            for cell in col:\n",
    "                try:  # Necessary to avoid error on empty cells\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(cell.value)\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2) * 1.2\n",
    "            worksheet.column_dimensions[column].width = adjusted_width\n",
    " # Convert pixels to character units\n",
    "        \n",
    "\n",
    "        # Apply auto filters starting from the 2nd row in the B column\n",
    "        #worksheet.auto_filter.ref = worksheet.dimensions\n",
    "        last_row = worksheet.max_row\n",
    "        last_column = worksheet.max_column\n",
    "        range_str = f\"B2:{get_column_letter(last_column)}{last_row}\"\n",
    "        worksheet.auto_filter.ref = range_str\n",
    "# Save the Excel file\n",
    "workbook.save(file_path)\n",
    "\n",
    "print(\"All DataFrames are written to {}\".format(file_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "85ba0fb9-1413-4c2c-ba2a-8e8c7b2bb209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\anaconda3\\Lib\\site-packages\\openpyxl\\worksheet\\_read_only.py:79: UserWarning: Data Validation extension is not supported and will be removed\n",
      "  for idx, row in parser.parse():\n"
     ]
    }
   ],
   "source": [
    "######################### Importing Input Files ##########################\n",
    "### Demand file to get the list of FGs and UOM\n",
    "Demand_file = pd.read_excel(demand_filepath)\n",
    "\n",
    "###Source of WtPerUnit\n",
    "NFC_master = pd.read_excel(NFC_master_file)\n",
    "KFC_master = pd.read_excel(KFC_master_file)\n",
    "GFC_master = pd.read_excel(GFC_master_file)\n",
    "\n",
    "########## Source For Booking Cost \n",
    "Booking_cost = pd.read_excel(budget_file, sheet_name='FG',usecols=\"A:F,IW:KO\", skiprows = 4)\n",
    "\n",
    "###### Source for trimming generated per KG ###############################\n",
    "\n",
    "Trim_prod =  pd.read_csv(trimming_output)\n",
    "# Trim_prod.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad881f87-1304-4520-a25d-4aa9e844360d",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### Logic: If trimming is being produced in multiple factories in multiple level, in that case we will take average values ###############\n",
    "# Create the pivot table\n",
    "trimming_table = Trim_prod.pivot_table(index='ASSEMB_ITEM_CODE', values='Trimming(in KG)', aggfunc='mean')\n",
    "# trimming_table.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7ab6da8a-2a6a-4e66-99bb-e5bf45f28389",
   "metadata": {},
   "outputs": [],
   "source": [
    "### The FG base list will be derived from Demand where retain flag is 1\n",
    "Demand_Base = Demand_file[Demand_file['Ret_Flag']==1]\n",
    "FG_List = Demand_Base[['FGSKUCode','UM']].drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1aa88cfa-a404-4b7c-b3bc-bf077c399bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Map SUb Category, Description, Wt UOM from combined master\n",
    "master = pd.concat([NFC_master[[' Item Code',' Description','Weight UOM','OPM Sub Category']], KFC_master[[' Item Code',' Description','Weight UOM','OPM Sub Category']],GFC_master[[' Item Code',' Description','Weight UOM','OPM Sub Category']]])\n",
    "# master.head()\n",
    "FG_Master = pd.merge(FG_List, master, left_on=['FGSKUCode'], \n",
    "                                   right_on=[' Item Code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baecbaac-9fd7-416b-9286-61746706480f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User.DESKTOP-JNFPIJ4\\AppData\\Local\\Temp\\ipykernel_15624\\792492109.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  Bk_Cst_base['Avg_Budget_cost']=Bk_Cst_base[['Total Cost.60','Total Cost.61','Total Cost.62','Total Cost.63','Total Cost.64','Total Cost.65','Total Cost.66','Total Cost.67','Total Cost.68','Total Cost.69','Total Cost.70','Total Cost.71']].fillna(0).astype('float64').mean(axis= 1)\n"
     ]
    }
   ],
   "source": [
    "### Average Booking cost is taken for all the months and accross all the factories and then mapped \n",
    "\n",
    "Bk_Cst_base =Booking_cost[['Entity','Item Code','Description','UOM','Currency','OH','Total Cost.60','Total Cost.61','Total Cost.62','Total Cost.63','Total Cost.64','Total Cost.65','Total Cost.66','Total Cost.67','Total Cost.68','Total Cost.69','Total Cost.70','Total Cost.71']]\n",
    "Bk_Cst_base['Avg_Budget_cost']=Bk_Cst_base[['Total Cost.60','Total Cost.61','Total Cost.62','Total Cost.63','Total Cost.64','Total Cost.65','Total Cost.66','Total Cost.67','Total Cost.68','Total Cost.69','Total Cost.70','Total Cost.71']].fillna(0).astype('float64').mean(axis= 1)\n",
    "Bk_Cst_base = Bk_Cst_base[['Entity', 'Item Code', 'Description', 'UOM', 'Currency','Avg_Budget_cost']]\n",
    "Bk_Cst_base1 = Bk_Cst_base.groupby(['Item Code','UOM', 'Currency'])['Avg_Budget_cost'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "43c27931-1d64-473f-bd70-5765f280f7f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "###UOMPerPallet and trimmingKGperunit kept blank as logic is not clear yet\n",
    "FG_Master_base = pd.merge(FG_Master, Bk_Cst_base1, left_on=['FGSKUCode'], \n",
    "                                   right_on=['Item Code'], how='left')\n",
    "FG_Master_base =FG_Master_base[['FGSKUCode', ' Description','OPM Sub Category','UM','Weight UOM','Avg_Budget_cost']].drop_duplicates()\n",
    "\n",
    "# Merge the pivot table with FG_master_base based on ASSEMB_ITEM_CODE and FGSKUCode\n",
    "FG_Master_base = pd.merge(trimming_table, FG_Master_base, left_index=True, right_on='FGSKUCode', how='right')\n",
    "FG_Master_base['UOMPerPallet'] =np.nan \n",
    "\n",
    "FG_Master_base =FG_Master_base[['FGSKUCode', ' Description','OPM Sub Category','UM','Weight UOM','UOMPerPallet','Avg_Budget_cost','Trimming(in KG)']]\n",
    "# Rename columns\n",
    "FG_Master_base = FG_Master_base.rename(columns={'FGSKUCode':'FG Code', \n",
    "' Description':'FG Desc', \n",
    "'OPM Sub Category':'FG Cat', \n",
    "'UM':'FG UOM', \n",
    "'Weight UOM':'WtPerUnit',\n",
    "'UOMPerPallet':'UOMPerPallet', \n",
    "'Avg_Budget_cost':'Book Cost', \n",
    "'Trimming(in KG)':'TrimKGPerUnit'})\n",
    "# FG_Master_base['retain_flag'] = FG_Master_base.apply(lambda row: 0 if pd.isnull(row['WtPerUnit']) or pd.isnull(row['Book Cost']) else 1, axis=1)\n",
    "# FG_Master_base\n",
    "FG_Master_base['retain_flag']=1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d26eae46-e750-4453-82ea-51b1f9cbedf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All DataFrames are written to 29_04_2024_FG-SKU.xlsx\n"
     ]
    }
   ],
   "source": [
    "###################### Formatting and final Output ####################################\n",
    "\n",
    "# Write the name of dataframe and tab name that you want in excel\n",
    "dataframes = {\n",
    "    'FG SKU': FG_Master_base,\n",
    "   }\n",
    "\n",
    "# Specify the path to save your Excel file\n",
    "file_path = r'29_04_2024_FG-SKU.xlsx'\n",
    "# Using ExcelWriter to write each DataFrame to a separate sheet\n",
    "with pd.ExcelWriter(file_path, engine='openpyxl') as writer:\n",
    "    for sheet_name, dataframe in dataframes.items():\n",
    "        dataframe.to_excel(writer, sheet_name=sheet_name, index=False)\n",
    "\n",
    "    # Load the workbook and apply formatting\n",
    "    workbook = writer.book\n",
    "    for sheet_name in dataframes.keys():\n",
    "        worksheet = workbook[sheet_name]\n",
    "        worksheet.sheet_view.showGridLines = False  # Remove gridlines\n",
    "\n",
    "        # Add one row and column at the top\n",
    "        worksheet.insert_rows(1)\n",
    "        worksheet.insert_cols(1)\n",
    "        worksheet.cell(row=1, column=1)\n",
    "\n",
    "        # Add table borders\n",
    "        border = Border(left=Side(style='thin'), \n",
    "                        right=Side(style='thin'), \n",
    "                        top=Side(style='thin'), \n",
    "                        bottom=Side(style='thin'))\n",
    "        for row in worksheet.iter_rows(min_row=2, min_col=2, max_col=worksheet.max_column):\n",
    "            for cell in row:\n",
    "                cell.border = border\n",
    "\n",
    "        \n",
    "# Set light blue color for headers\n",
    "        for cell in worksheet.iter_cols(min_row=2, min_col=2):\n",
    "            cell[0].fill = PatternFill(start_color=\"ADD8E6\", end_color=\"ADD8E6\", fill_type=\"solid\")  # Light blue\n",
    "    \n",
    "        # Remove borders for the extra added row and column at the top\n",
    "        for cell in worksheet['A1:C1'][0]:\n",
    "            cell.border = None\n",
    "# Autofit columns\n",
    "        for col in worksheet.columns:\n",
    "            max_length = 0\n",
    "            column = col[0].column_letter  # Get the column name\n",
    "            for cell in col:\n",
    "                try:  # Necessary to avoid error on empty cells\n",
    "                    if len(str(cell.value)) > max_length:\n",
    "                        max_length = len(cell.value)\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = (max_length + 2) * 1.2\n",
    "            worksheet.column_dimensions[column].width = adjusted_width\n",
    " # Convert pixels to character units\n",
    "        \n",
    "\n",
    "        # Apply auto filters starting from the 2nd row in the B column\n",
    "        #worksheet.auto_filter.ref = worksheet.dimensions\n",
    "        last_row = worksheet.max_row\n",
    "        last_column = worksheet.max_column\n",
    "        range_str = f\"B2:{get_column_letter(last_column)}{last_row}\"\n",
    "        worksheet.auto_filter.ref = range_str\n",
    "# Save the Excel file\n",
    "workbook.save(file_path)\n",
    "\n",
    "print(\"All DataFrames are written to {}\".format(file_path))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc1e4e2-4d73-40e1-9169-d49a6d757a72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a98c7ba-7e38-43bc-94e8-203c3156b1c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8d049b-b6ef-4146-8674-e588ef62c288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
