{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8664911b-61c4-459f-93ff-ebb820fa36dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Importing all dependencies \n",
    "import pandas as pd\n",
    "import datetime\n",
    "import warnings\n",
    "\n",
    " \n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028afb55-f0cf-4e1d-aefe-0ef2c20914dd",
   "metadata": {},
   "source": [
    "#### Raw Material Data Preprocessing: Independent Step\n",
    "\n",
    "This stage encompasses preprocessing tasks and additional calculations, including the conversion of costs into current exchange rate.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9dd8a604-5a31-4d6e-9934-564c693f9118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Status</th>\n",
       "      <th>ID Code</th>\n",
       "      <th>Code</th>\n",
       "      <th>Description</th>\n",
       "      <th>2024 Volume</th>\n",
       "      <th>Entity</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Category</th>\n",
       "      <th>Responsible</th>\n",
       "      <th>Management</th>\n",
       "      <th>...</th>\n",
       "      <th>2023-03-01 00:00:00</th>\n",
       "      <th>2023-04-01 00:00:00</th>\n",
       "      <th>2023-05-01 00:00:00</th>\n",
       "      <th>2023-06-01 00:00:00</th>\n",
       "      <th>2023-07-01 00:00:00</th>\n",
       "      <th>2023-08-01 00:00:00</th>\n",
       "      <th>2023-09-01 00:00:00</th>\n",
       "      <th>2023-10-01 00:00:00</th>\n",
       "      <th>2023-11-01 00:00:00</th>\n",
       "      <th>2023-12-01 00:00:00</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1001101127GFC</td>\n",
       "      <td>1001101127</td>\n",
       "      <td>CHICKEN TRIMMING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GFC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.937972</td>\n",
       "      <td>1.877684</td>\n",
       "      <td>1.812675</td>\n",
       "      <td>1.802160</td>\n",
       "      <td>1.721858</td>\n",
       "      <td>1.867997</td>\n",
       "      <td>1.810403</td>\n",
       "      <td>2.058041</td>\n",
       "      <td>2.113722</td>\n",
       "      <td>2.145325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>7012100126GFC</td>\n",
       "      <td>7012100126</td>\n",
       "      <td>WHITE MILKY BIG BAGS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GFC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012106251GFC</td>\n",
       "      <td>2012106251</td>\n",
       "      <td>LABEL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GFC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009536</td>\n",
       "      <td>0.009536</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>0.009533</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.009531</td>\n",
       "      <td>0.009531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012114588GFC</td>\n",
       "      <td>2012114588</td>\n",
       "      <td>ROYAL CO-PACKING CARTONS</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GFC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.881423</td>\n",
       "      <td>0.881423</td>\n",
       "      <td>0.881423</td>\n",
       "      <td>0.881423</td>\n",
       "      <td>0.881423</td>\n",
       "      <td>0.881423</td>\n",
       "      <td>0.881423</td>\n",
       "      <td>0.839405</td>\n",
       "      <td>0.833862</td>\n",
       "      <td>0.697000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2012104429GFC</td>\n",
       "      <td>2012104429</td>\n",
       "      <td>TAPE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>GFC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.878639</td>\n",
       "      <td>4.878704</td>\n",
       "      <td>4.878492</td>\n",
       "      <td>4.878476</td>\n",
       "      <td>4.878476</td>\n",
       "      <td>4.878437</td>\n",
       "      <td>4.878435</td>\n",
       "      <td>4.878435</td>\n",
       "      <td>4.879073</td>\n",
       "      <td>4.879505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011114801NFCC</td>\n",
       "      <td>2011114801</td>\n",
       "      <td>CHICKEN BURGER BAG N3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NFCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.047658</td>\n",
       "      <td>0.047658</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>0.049157</td>\n",
       "      <td>0.046049</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.045475</td>\n",
       "      <td>0.047485</td>\n",
       "      <td>0.048416</td>\n",
       "      <td>0.048944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011114914NFCC</td>\n",
       "      <td>2011114914</td>\n",
       "      <td>FALAFEL AMER. ROLL N3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NFCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.125824</td>\n",
       "      <td>0.125824</td>\n",
       "      <td>0.124177</td>\n",
       "      <td>0.124177</td>\n",
       "      <td>0.124177</td>\n",
       "      <td>0.124177</td>\n",
       "      <td>0.124177</td>\n",
       "      <td>0.128557</td>\n",
       "      <td>0.129006</td>\n",
       "      <td>0.129341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>NaN</td>\n",
       "      <td>2011995254NFCC</td>\n",
       "      <td>2011995254</td>\n",
       "      <td>ROYAL BREADED REGULAR CHICKEN FILLET ROLL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NFCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.117333</td>\n",
       "      <td>0.117333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4001370230NFCC</td>\n",
       "      <td>4001370230</td>\n",
       "      <td>Chicken Nuggets 400G (18*1*400Gm)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NFCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>18.378569</td>\n",
       "      <td>16.806015</td>\n",
       "      <td>14.143222</td>\n",
       "      <td>15.959817</td>\n",
       "      <td>15.479329</td>\n",
       "      <td>15.612539</td>\n",
       "      <td>15.613236</td>\n",
       "      <td>15.742542</td>\n",
       "      <td>16.090526</td>\n",
       "      <td>16.199821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1485</th>\n",
       "      <td>NaN</td>\n",
       "      <td>4001370243NFCC</td>\n",
       "      <td>4001370243</td>\n",
       "      <td>NABATI CHICKEN NUGGETS 270G (18*1*270GM)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NFCC</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>20.469075</td>\n",
       "      <td>19.023999</td>\n",
       "      <td>19.078671</td>\n",
       "      <td>19.176176</td>\n",
       "      <td>19.378070</td>\n",
       "      <td>19.982070</td>\n",
       "      <td>19.303764</td>\n",
       "      <td>16.767084</td>\n",
       "      <td>16.740273</td>\n",
       "      <td>16.718953</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1486 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Status         ID Code        Code  \\\n",
       "0       NaN   1001101127GFC  1001101127   \n",
       "1       NaN   7012100126GFC  7012100126   \n",
       "2       NaN   2012106251GFC  2012106251   \n",
       "3       NaN   2012114588GFC  2012114588   \n",
       "4       NaN   2012104429GFC  2012104429   \n",
       "...     ...             ...         ...   \n",
       "1481    NaN  2011114801NFCC  2011114801   \n",
       "1482    NaN  2011114914NFCC  2011114914   \n",
       "1483    NaN  2011995254NFCC  2011995254   \n",
       "1484    NaN  4001370230NFCC  4001370230   \n",
       "1485    NaN  4001370243NFCC  4001370243   \n",
       "\n",
       "                                    Description  2024 Volume Entity  \\\n",
       "0                              CHICKEN TRIMMING          NaN    GFC   \n",
       "1                          WHITE MILKY BIG BAGS          NaN    GFC   \n",
       "2                                         LABEL          NaN    GFC   \n",
       "3                      ROYAL CO-PACKING CARTONS          NaN    GFC   \n",
       "4                                          TAPE          NaN    GFC   \n",
       "...                                         ...          ...    ...   \n",
       "1481                      CHICKEN BURGER BAG N3          NaN   NFCC   \n",
       "1482                      FALAFEL AMER. ROLL N3          NaN   NFCC   \n",
       "1483  ROYAL BREADED REGULAR CHICKEN FILLET ROLL          NaN   NFCC   \n",
       "1484          Chicken Nuggets 400G (18*1*400Gm)          NaN   NFCC   \n",
       "1485   NABATI CHICKEN NUGGETS 270G (18*1*270GM)          NaN   NFCC   \n",
       "\n",
       "     Subcategory Category Responsible Management  ... 2023-03-01 00:00:00  \\\n",
       "0            NaN      NaN         NaN        NaN  ...            1.937972   \n",
       "1            NaN      NaN         NaN        NaN  ...            0.000000   \n",
       "2            NaN      NaN         NaN        NaN  ...            0.009536   \n",
       "3            NaN      NaN         NaN        NaN  ...            0.881423   \n",
       "4            NaN      NaN         NaN        NaN  ...            4.878639   \n",
       "...          ...      ...         ...        ...  ...                 ...   \n",
       "1481         NaN      NaN         NaN        NaN  ...            0.047658   \n",
       "1482         NaN      NaN         NaN        NaN  ...            0.125824   \n",
       "1483         NaN      NaN         NaN        NaN  ...            0.117333   \n",
       "1484         NaN      NaN         NaN        NaN  ...           18.378569   \n",
       "1485         NaN      NaN         NaN        NaN  ...           20.469075   \n",
       "\n",
       "     2023-04-01 00:00:00 2023-05-01 00:00:00 2023-06-01 00:00:00  \\\n",
       "0               1.877684            1.812675            1.802160   \n",
       "1               0.000000            0.000000            0.000000   \n",
       "2               0.009536            0.009533            0.009533   \n",
       "3               0.881423            0.881423            0.881423   \n",
       "4               4.878704            4.878492            4.878476   \n",
       "...                  ...                 ...                 ...   \n",
       "1481            0.047658            0.049157            0.049157   \n",
       "1482            0.125824            0.124177            0.124177   \n",
       "1483            0.117333            0.117333            0.117333   \n",
       "1484           16.806015           14.143222           15.959817   \n",
       "1485           19.023999           19.078671           19.176176   \n",
       "\n",
       "     2023-07-01 00:00:00  2023-08-01 00:00:00  2023-09-01 00:00:00  \\\n",
       "0               1.721858             1.867997             1.810403   \n",
       "1               0.000000             0.000000             0.000000   \n",
       "2               0.009533             0.009531             0.009531   \n",
       "3               0.881423             0.881423             0.881423   \n",
       "4               4.878476             4.878437             4.878435   \n",
       "...                  ...                  ...                  ...   \n",
       "1481            0.046049             0.045475             0.045475   \n",
       "1482            0.124177             0.124177             0.124177   \n",
       "1483            0.117333             0.117333             0.117333   \n",
       "1484           15.479329            15.612539            15.613236   \n",
       "1485           19.378070            19.982070            19.303764   \n",
       "\n",
       "      2023-10-01 00:00:00  2023-11-01 00:00:00  2023-12-01 00:00:00  \n",
       "0                2.058041             2.113722             2.145325  \n",
       "1                0.000000             0.000000             0.000000  \n",
       "2                0.009531             0.009531             0.009531  \n",
       "3                0.839405             0.833862             0.697000  \n",
       "4                4.878435             4.879073             4.879505  \n",
       "...                   ...                  ...                  ...  \n",
       "1481             0.047485             0.048416             0.048944  \n",
       "1482             0.128557             0.129006             0.129341  \n",
       "1483             0.117333             0.117333             0.117333  \n",
       "1484            15.742542            16.090526            16.199821  \n",
       "1485            16.767084            16.740273            16.718953  \n",
       "\n",
       "[1486 rows x 27 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###### RM data Processing #######\n",
    "\n",
    "##### Reading Default/ Template data #######\n",
    "\n",
    "################ RM Budgeted Cost Input Files ##################################\n",
    "\n",
    "#Read BUdget Data\n",
    "df_nfc = pd.read_excel(r\"PROTEIN_COGS_FORECAST-Q4+2024_BUDGET-TP3_V16.01.xlsx\", sheet_name='NFC_BOM',usecols=\"A:I,AW:BH\", skiprows = 3)\n",
    "df_kfc = pd.read_excel(r\"PROTEIN_COGS_FORECAST-Q4+2024_BUDGET-TP3_V16.01.xlsx\", sheet_name='KFC_BOM',usecols=\"A:I,AW:BH\", skiprows = 3)\n",
    "df_gfc = pd.read_excel(r\"PROTEIN_COGS_FORECAST-Q4+2024_BUDGET-TP3_V16.01.xlsx\", sheet_name='GFC_BOM',usecols=\"A:I,AW:BH\", skiprows = 3)\n",
    "\n",
    "################## Item Cost Data ###########################################\n",
    "\n",
    "# Read Item Cost data\n",
    "##### Logic: Only Dec-23 Item Cost/ Consumption Costs will be used \n",
    "df_gfc_i = pd.read_excel(r'ITEM COST GFC DEC-23.xls')\n",
    "df_kfc_i = pd.read_excel(r'ITEM COST KFC DEC-23.xls')\n",
    "df_nfc_i = pd.read_excel(r'ITEM COST NFC DEC-23.xls')\n",
    "\n",
    "########################### Forecsted Cost Data ###############################\n",
    "\n",
    "# Read Forecasted Cost Data\n",
    "# df_frct =pd.read_excel(r\"Protein Commodities Impact_110324 (1) (1).xlsx\",sheet_name='Dashboard',usecols=\"A:AA\",skiprows=1)\n",
    "### Updating with RM 2023 price\n",
    "# df_frct =pd.read_excel(r\"24_04_RM Prices_2023 v2.xlsx\",sheet_name='Dashboard',usecols=\"A:AA\",skiprows=1)\n",
    "df_frct =pd.read_excel(r\"23_04_2024 RM Prices for 2023 Backtest v4.xlsx\",sheet_name='Dashboard',usecols=\"A:AA\",skiprows=1)\n",
    "df_frct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40f3311e-0c7b-4417-9712-0360b57b41e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "####### One-time data (Entity Master Data) ##### \n",
    "# Define the data for the entity mapping\n",
    "data = {\n",
    "    'Entity': ['GFI', 'NFCM', 'GFC', 'KFC', 'NFCC'],\n",
    "    'Factory code': ['GFC', 'NFC', 'GFC', 'KFC', 'NFC']\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "df_entity_mapping = pd.DataFrame(data)\n",
    "# df_entity_mapping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57857c5e-8d5d-43cc-8020-c64fd2646572",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''' List out functions '''\n",
    "##### Exchange Rates As inputs #####\n",
    "def get_conversion_rates():\n",
    "    \"\"\"\n",
    "    Get conversion rates from user input with default values.\n",
    "\n",
    "    Returns:\n",
    "    - dict: A dictionary containing conversion rates for each factory.\n",
    "    \"\"\"\n",
    "    use_default = input(\"Do you want to use default values? The following Conversion rates will be applied 'KFC': 0.306001, 'NFC': 3.75, 'GFC': 3.6725 (Y/N): \").upper()\n",
    "\n",
    "    if use_default == 'Y':\n",
    "        # conversion_rates = {'KFC': 0.306001, 'NFC': 3.75, 'GFC': 3.6725}\n",
    "        conversion_rates = {'KFC': 3.26796317659, 'NFC': 0.26666666666, 'GFC': 0.2722940776}\n",
    "    else:\n",
    "        conversion_rates = {}\n",
    "        conversion_rates['GFC'] = float(input(\"Enter conversion rate for GFC (1 AED= ? USD): \"))\n",
    "        conversion_rates['KFC'] = float(input(\"Enter conversion rate for KFC (1 KWD = ? USD): \"))\n",
    "        conversion_rates['NFC'] = float(input(\"Enter conversion rate for NFC (1 SAR = ? USD): \"))\n",
    "    \n",
    "    return conversion_rates\n",
    "\n",
    "# Function to convert date string to datetime\n",
    "def convert_to_datetime(date_string):\n",
    "    date_format = date_format_dict.get(date_string)\n",
    "    if date_format:\n",
    "        return datetime.datetime.strptime(date_string, date_format)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b14625f-4345-45e2-8469-72fd37e8abf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to use default values? The following Conversion rates will be applied 'KFC': 0.306001, 'NFC': 3.75, 'GFC': 3.6725 (Y/N):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently used Exchange rates are : {'KFC': 3.26796317659, 'NFC': 0.26666666666, 'GFC': 0.2722940776}\n",
      "Exchnage rates added\n",
      "Data Unpivoted\n",
      "Derive Budgeted cost per unit of required Qty (USD) - Done\n",
      "RM Budgeted cost conversion is Successful!!!\n"
     ]
    }
   ],
   "source": [
    "#### RM Budgeted Cost Processing ####\n",
    "\n",
    "try:\n",
    "\n",
    "    #Add FactoryCode column\n",
    "    df_nfc.insert(df_nfc.columns.get_loc('Required Qty'), 'FactCode', 'NFC')\n",
    "    df_kfc.insert(df_kfc.columns.get_loc('Required Qty'), 'FactCode', 'KFC')\n",
    "    df_gfc.insert(df_gfc.columns.get_loc('Required Qty'), 'FactCode', 'GFC')\n",
    "\n",
    "    ### Take exchange rates from the input data\n",
    "\n",
    "    conversion_rates = get_conversion_rates()\n",
    "    print('Currently used Exchange rates are :', conversion_rates)\n",
    "\n",
    "    df_nfc.insert(df_nfc.columns.get_loc('FactCode'), 'Con_rate', conversion_rates['NFC'])\n",
    "    df_kfc.insert(df_kfc.columns.get_loc('FactCode'), 'Con_rate', conversion_rates['KFC'])\n",
    "    df_gfc.insert(df_gfc.columns.get_loc('FactCode'), 'Con_rate', conversion_rates['GFC'])\n",
    "\n",
    "    print ('Exchnage rates added')\n",
    "\n",
    "    ## Unpivot tables \n",
    "    # NFC unpivot\n",
    "    up_df_nfc = pd.melt(df_nfc, id_vars=['Item Code', 'Description', 'UOM', 'RM Category', 'Type',\n",
    "                                        'Ingredient Item', 'Description.1', 'UOM.1', 'Con_rate', 'FactCode',\n",
    "                                        'Required Qty'], var_name='Month', value_name='Budgeted_Cost')\n",
    "\n",
    "    #KFC unpivot\n",
    "    up_df_kfc = pd.melt(df_kfc, id_vars=['Item Code', 'Description', 'UOM', 'RM Category', 'Type',\n",
    "                                        'Ingredient Item', 'Description.1', 'UOM.1', 'Con_rate', 'FactCode',\n",
    "                                        'Required Qty'], var_name='Month', value_name='Budgeted_Cost')\n",
    "\n",
    "    # GFC Unpivot\n",
    "    up_df_gfc = pd.melt(df_gfc, id_vars=['Item Code', 'Description', 'UOM', 'RM Category', 'Type',\n",
    "                                        'Ingredient Item', 'Description.1', 'UOM.1', 'Con_rate', 'FactCode',\n",
    "                                        'Required Qty'], var_name='Month', value_name='Budgeted_Cost')\n",
    "\n",
    "    print('Data Unpivoted')\n",
    "\n",
    "    #### Convert all the unpivot tables' months into month numbers\n",
    "    #### NFC Data\n",
    "    # Convert the date into datetime\n",
    "    up_df_nfc['Month1'] = pd.to_datetime(up_df_nfc['Month'])\n",
    "    # Extract the month number\n",
    "    up_df_nfc['MthNum'] = up_df_nfc['Month1'].dt.month\n",
    "\n",
    "    #### KFC Data\n",
    "    # Convert the date into datetime\n",
    "    up_df_kfc['Month1'] = pd.to_datetime(up_df_kfc['Month'])\n",
    "    # Extract the month number\n",
    "    up_df_kfc['MthNum'] = up_df_kfc['Month1'].dt.month\n",
    "\n",
    "    #### GFC Data\n",
    "    # Convert the date into datetime\n",
    "    up_df_gfc['Month1'] = pd.to_datetime(up_df_gfc['Month'])\n",
    "    # Extract the month number\n",
    "    up_df_gfc['MthNum'] = up_df_gfc['Month1'].dt.month\n",
    "\n",
    "    #####Join 3tables into one and then calculate the Budgeted cost per unit of required Qty\n",
    "    ####### Formula to be used\n",
    "    ## Budgeted cost per unit of required Qty (USD) = Budgeted cost* Con_rate/Required Qty\n",
    "\n",
    "    #Step-1: Join the 3 tables into one\n",
    "    bud_df = pd.concat([up_df_nfc, up_df_kfc, up_df_gfc], ignore_index=True)\n",
    "\n",
    "    #Step-2: Derive Budgeted cost per unit of required Qty (USD)\n",
    "    # bud_df['Bud_Cost_USD'] = (bud_df['Budgeted_Cost']*bud_df['Con_rate'])/bud_df['Required Qty']\n",
    "    bud_df['Bud_Cost_USD'] = None\n",
    "    print('Derive Budgeted cost per unit of required Qty (USD) - Done')\n",
    "\n",
    "    bud_df_final =  bud_df[['FactCode','MthNum','RM Category', 'Type',\n",
    "       'Ingredient Item', 'Description.1', 'UOM.1','Bud_Cost_USD']].drop_duplicates()\n",
    "    \n",
    "     # Create a pivot table with 'Category' as rows and 'Value' as values, and aggregate using sum\n",
    "    bud_df_final1 = pd.pivot_table(bud_df_final, index=['FactCode','MthNum', 'Type',\n",
    "       'Ingredient Item', 'Description.1', 'UOM.1'], values='Bud_Cost_USD', aggfunc='mean')\n",
    "    ######### Extra line for 2023 data \n",
    "    bud_df_final1['Bud_Cost_USD'] = None\n",
    "    ####Return the output into an excel\n",
    "    bud_df_final1.head()\n",
    "    bud_df_final1.to_csv('RM Budgeted cost.csv')\n",
    "    print ('RM Budgeted cost conversion is Successful!!!')\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "       print (\"RM Budgeted cost processing failed due to the following error: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ec298a6c-435d-4ced-bdd7-2b78291f83fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bud_df_final1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f9e96be-5621-4196-9b5a-fe799f4c635e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to use default values? The following Conversion rates will be applied 'KFC': 0.306001, 'NFC': 3.75, 'GFC': 3.6725 (Y/N):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently used Exchange rates are : {'KFC': 3.26796317659, 'NFC': 0.26666666666, 'GFC': 0.2722940776}\n",
      "Exchage rates applied\n",
      "Item cost processing successful !!!\n"
     ]
    }
   ],
   "source": [
    "################################ Item Cost Data Transformation ##########################\n",
    "\n",
    "try: \n",
    "    ### Convert into Pivot and add conversion rates\n",
    "    # NFC pivot\n",
    "    up_df_nfc = pd.pivot_table(df_nfc_i, index=['ORGANIZATION_CODE', 'PERIOD_CODE', 'ITEM_CODE', 'DESCRIPTION'], values='CMPNT_COST', aggfunc='sum')\n",
    "    #KFC pivot\n",
    "    up_df_kfc = pd.pivot_table(df_kfc_i, index=['ORGANIZATION_CODE', 'PERIOD_CODE', 'ITEM_CODE', 'DESCRIPTION'], values='CMPNT_COST', aggfunc='sum')\n",
    "    #GFC pivot\n",
    "    up_df_gfc = pd.pivot_table(df_gfc_i, index=['ORGANIZATION_CODE', 'PERIOD_CODE', 'ITEM_CODE', 'DESCRIPTION'], values='CMPNT_COST', aggfunc='sum')\n",
    "\n",
    "    fin_df_nfc = up_df_nfc.reset_index()\n",
    "    fin_df_kfc = up_df_kfc.reset_index()\n",
    "    fin_df_gfc = up_df_gfc.reset_index()\n",
    "\n",
    "    ### Take exchange rates from the input data\n",
    "\n",
    "    conversion_rates = get_conversion_rates()\n",
    "    print('Currently used Exchange rates are :', conversion_rates)\n",
    "\n",
    "    fin_df_nfc.insert(fin_df_nfc.columns.get_loc('ORGANIZATION_CODE'), 'Con_rate', conversion_rates['NFC'])\n",
    "    fin_df_kfc.insert(fin_df_kfc.columns.get_loc('ORGANIZATION_CODE'), 'Con_rate', conversion_rates['KFC'])\n",
    "    fin_df_gfc.insert(fin_df_gfc.columns.get_loc('ORGANIZATION_CODE'), 'Con_rate', conversion_rates['GFC'])\n",
    "\n",
    "    print ('Exchage rates applied')\n",
    "\n",
    "    #### Join the 3 tables into one and then convert them into USD using \n",
    "    cons_df = pd.concat([fin_df_nfc, fin_df_kfc, fin_df_gfc], ignore_index=True)\n",
    "    # cons_df['Consumption cost ($USD)'] = cons_df['CMPNT_COST']*cons_df['Con_rate']\n",
    "    cons_df['Consumption cost ($USD)']= None\n",
    "    cons_df.head()\n",
    "\n",
    "    ### Export as a new output table \n",
    "    ### Export the Item cost data \n",
    "    cons_df.to_csv('Item_cost_Processed.csv',index=False)\n",
    "    print('Item cost processing successful !!!')\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "       print (\"Item cost processing failed due to the following error: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f3857d2-86bd-4030-bc71-053b23c55f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_frct.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "919df2e6-1db9-45b8-85b6-71f212839115",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All entities are mapped in the Master Data\n",
      "Month Number conversion done\n",
      "Forecasted cost processing successful !!!\n"
     ]
    }
   ],
   "source": [
    "##################### RM Forecasted Price Processing ##################\n",
    "try: \n",
    "\n",
    "    df_frct.columns = df_frct.columns.astype(str)\n",
    "\n",
    "    # Adjust value_vars list to only include month columns\n",
    "    # value_vars_adjusted = [\n",
    "    #     'Jan-24', '2024-02-01 00:00:00', 'Mar-24', 'Apr-24', 'May-24',\n",
    "    #     'Jun-24', 'Jul-24', 'Aug-24', 'Sep-24', 'Oct-24', 'Nov-24', 'Dec-24'\n",
    "    # ]\n",
    "    value_vars_adjusted = [\n",
    "        '2023-01-01 00:00:00', '2023-02-01 00:00:00',\n",
    "       '2023-03-01 00:00:00', '2023-04-01 00:00:00', '2023-05-01 00:00:00',\n",
    "       '2023-06-01 00:00:00', '2023-07-01 00:00:00', '2023-08-01 00:00:00',\n",
    "       '2023-09-01 00:00:00', '2023-10-01 00:00:00', '2023-11-01 00:00:00',\n",
    "       '2023-12-01 00:00:00'\n",
    "    ]\n",
    "\n",
    "    # Melt the DataFrame using the adjusted value_vars list\n",
    "    df2=pd.melt(df_frct, \n",
    "                        id_vars=['Status', 'ID Code', 'Code', 'Description', '2024 Volume',\n",
    "                                'Entity', 'Subcategory', 'Category', 'Responsible', \n",
    "                                'Management', 'Business Category', 'Reporting Currency', \n",
    "                                'UOM-BUD', 'UOM-act', 'CORRECTION'],\n",
    "                        value_vars=value_vars_adjusted,\n",
    "                        var_name='Month', \n",
    "                        value_name='Value')\n",
    "    \n",
    "    # df3=df2.groupby(['Code','Entity','Reporting Currency','UOM-BUD','Month'])['Value'].sum().reset_index()\n",
    "    # df3=df2.groupby(['Code','Entity','UOM-BUD','Month'])['Value'].sum().reset_index()\n",
    "    df3=df2.groupby(['Code','Entity','Month'])['Value'].sum().reset_index()\n",
    "    df3['Value'] = pd.to_numeric(df3['Value'], errors='coerce')\n",
    "\n",
    "    # Add new column 'Value-TON revised'\n",
    "    # df3['Value-TON revised'] = df3.apply(lambda row: row['Value'] / 1000 if row['UOM-BUD'] == 'TON' else row['Value'], axis=1)\n",
    "    df3['Value-TON revised'] = df3['Value']\n",
    "    # date_format_dict = {\n",
    "    # '2024-02-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    # 'Apr-24': '%b-%y',\n",
    "    # 'Aug-24': '%b-%y',\n",
    "    # 'Dec-24': '%b-%y',\n",
    "    # 'Jan-24': '%b-%y',\n",
    "    # 'Jul-24': '%b-%y',\n",
    "    # 'Jun-24': '%b-%y',\n",
    "    # 'Mar-24': '%b-%y',\n",
    "    # 'May-24': '%b-%y',\n",
    "    # 'Nov-24': '%b-%y',\n",
    "    # 'Oct-24': '%b-%y',\n",
    "    # 'Sep-24': '%b-%y'\n",
    "    # }\n",
    "    \n",
    "    date_format_dict = {\n",
    "    '2023-01-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-02-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-03-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-04-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-05-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-06-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-07-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-08-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-09-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-10-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-11-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    '2023-12-01 00:00:00': '%Y-%m-%d %H:%M:%S',\n",
    "    }\n",
    "\n",
    "\n",
    "    # Apply the function to 'Month' column\n",
    "    df3['Month'] = df3['Month'].apply(convert_to_datetime)\n",
    "\n",
    "    # Compare unique values of the 'Entity' column in df_entity_mapping with df_frct\n",
    "    unmapped_entities = df3[~df3['Entity'].isin(df_entity_mapping['Entity'])]['Entity'].unique()\n",
    "\n",
    "    # Print the unmapped entities\n",
    "    if len(unmapped_entities) > 0:\n",
    "        print(\"These entities will be ignored:\")\n",
    "        print (\"To map more entities please update Entity Mapping Master\")\n",
    "        for entity in unmapped_entities:\n",
    "            print(\"-\", entity)\n",
    "            \n",
    "    else:\n",
    "        print(\"All entities are mapped in the Master Data\")\n",
    "    \n",
    "    df_frct_final= pd.merge(df3, df_entity_mapping, on='Entity', how='inner')\n",
    "    df_frct_final['Month1']= pd.to_datetime(df_frct_final['Month']).dt.month\n",
    "    df_frct_final['Month1']= df_frct_final['Month1'].astype('int64')\n",
    "    df_frct_final.head()\n",
    "\n",
    "    print('Month Number conversion done')    \n",
    "\n",
    "    df_frct_final.to_excel('forecast_cost.xlsx',index=False)\n",
    "    print('Forecasted cost processing successful !!!')\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "       print (\"Forecasted cost processing failed due to the following error: \", e)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2889768-fca3-4e1e-a0ec-558e8a8e4d05",
   "metadata": {},
   "source": [
    "#### RM Price Mapping \n",
    "\n",
    "Raw Material Price Mapping comprises the following stages\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "1. Extract FG SKU + Factory combinations to associate with the Bill of Materials (m M1.\n",
    "2. Generate filtered BOM-1 and BOM-2 based on BOM availabor M4.\n",
    "3. Compile a list of unique Factory-Raw Material (RM) combinations referenced in the filtered BOM.\n",
    "4. Employ the list to link 12-month costs for each RM (Raw Material) from the supply base data.\n",
    "5. Calculate the average cost for each RM at the facto which can be taken as an input to the Top 80% BOM calculationt for M4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0b4c2e2f-16a7-43e0-bfae-070bf9d18c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Template Files ####\n",
    "#### Not Subject to change ######\n",
    "####The following tables will be used as templates to check against the new input data provided and some one-time tables are also listed here #####\n",
    "\n",
    "Capacity_template = 'Capacity_DD_Filtered.xlsx'\n",
    "BOM1_template = 'BOM1.xlsx'\n",
    "BOM2_template = 'BOM2.xlsx'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "164cb3eb-fd51-45bb-a713-f16b7cb21970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#################### Key commodity List  (Master List) - One Time Data ###################################################\n",
    "# Define the data for the key commodities list- Logic confirmed from business\n",
    "data = {\n",
    "    'RM_Code': [1001101002, 1001101007, 1001101108, 1001102618],\n",
    "    'RM_Desc': ['BRAZILIAN BEEF FOREQUARTER', 'BRAZILIAN BEEF TRIMMING', 'CHICKEN BREAST', 'KUDU CHICKEN BREAST (1*15KG)']\n",
    "}\n",
    "\n",
    "# Create a pandas DataFrame\n",
    "key_commodities = pd.DataFrame(data)\n",
    "# key_commodities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6625312d-90e0-439e-a02e-4a5096b42313",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### One time Factory Mapping (Factory Mapping Master for BOM data) #####\n",
    "\n",
    "# def assign_factcode(row):\n",
    "#     if row['COMP_ORG'] in ['NF1', 'NF2']:\n",
    "#         return 'NFC'\n",
    "#     elif row['COMP_ORG'] == 'GFM':\n",
    "#         return 'GFC'\n",
    "#     elif row['COMP_ORG'] == 'KPF':\n",
    "#         return 'KFC'\n",
    "#     else:\n",
    "#         return None  # or whatever default value you want to assign for other cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "75310c1d-3386-43b0-b5ea-abdd7ab5e3fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' List of Functions Required '''\n",
    "### Define Required Functions for this data process ####\n",
    "\n",
    "#### Take input for the tables required for this data module ####\n",
    "def get_table_paths():\n",
    "\n",
    "    \"\"\"\n",
    "    No of Input files: 3\n",
    "    If the Input file is not specified takes templates as default tables.\n",
    "    \n",
    "    BOM1 : Flatten BOM1 data \n",
    "    BOM2: Flatten BOM2 data\n",
    "    Capacity File: File with line and throughput mapping at FG SKU level\n",
    "\n",
    "    \"\"\"  \n",
    "    # Default file paths\n",
    "    Capacity_template = 'Capacity_DD_Filtered.xlsx'\n",
    "    BOM1_template = 'BOM1.xlsx'\n",
    "    BOM2_template = 'BOM2.xlsx'\n",
    "    \n",
    "    # Ask if user wants to use default file paths\n",
    "    use_defaults = input(\"Do you want to use default file paths? (Y/N): \").upper()\n",
    "    \n",
    "    if use_defaults == 'Y':\n",
    "        \n",
    "        \n",
    "        capacity_file_path = Capacity_template\n",
    "        BOM1_file_path = BOM1_template\n",
    "        BOM2_file_path = BOM2_template\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Prompt user to input custom file paths\n",
    "        BOM1_file_path = input(\"Enter the path for BOM1 file : \")\n",
    "        BOM2_file_path = input(\"Enter the path for BOM2 file : \")\n",
    "        capacity_file_path = input(\"Enter the path for Capacity file: \")\n",
    "        \n",
    "           \n",
    "    return BOM1_file_path,BOM2_file_path, capacity_file_path\n",
    "\n",
    "\n",
    "##### Checks whether a list of columns to be verified exists within a given list of columns in a particular data frame - will be called inside \n",
    "##### 'process_dataframe' function\n",
    "\n",
    "def column_check(to_check, columns):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    This function checks whether a list of columns to be verified exists within a given list of columns. \n",
    "    It returns a list of columns that are not present in the given list.\n",
    "\n",
    "    Parameters:\n",
    "    - to_check (list): A list of columns to be verified.\n",
    "    - columns (list): A list of columns to check against.\n",
    "\n",
    "    Returns:\n",
    "    - not_present (list): A list containing columns from 'to_check' that are not present in 'columns'.\n",
    "    \n",
    "    Example:\n",
    "    to_check = ['column1', 'column2', 'column3']\n",
    "    columns = ['column1', 'column3', 'column4']\n",
    "    missing_columns = column_check(to_check, columns)\n",
    "    print(missing_columns)  # Output: ['column2']\n",
    "    \"\"\"\n",
    "    not_present = []\n",
    "\n",
    "    for i in to_check:\n",
    "        if i not in columns:\n",
    "            not_present.append(i)\n",
    "    return not_present\n",
    "\n",
    "\n",
    "##### Create a dictionary with predefined data types based on a DataFrame.- will be called inside 'check_data_types' functions\n",
    "\n",
    "def create_predefined_types(dataframe):\n",
    "    \"\"\"\n",
    "    Create a dictionary with predefined data types based on a DataFrame.\n",
    "    \n",
    "    Parameters:\n",
    "    - dataframe (DataFrame): The DataFrame to create predefined types from.\n",
    "    \n",
    "    Returns:\n",
    "    - predefined_types (dict): A dictionary where keys are column names and values are inferred data types.\n",
    "    \"\"\"\n",
    "    predefined_types = {}\n",
    "    \n",
    "    for column in dataframe.columns:\n",
    "        column_type = str(dataframe[column].dtype)\n",
    "        predefined_types[column] = column_type\n",
    "    \n",
    "    return predefined_types\n",
    "\n",
    "\n",
    "######### Check data types of imported data against predefined types.\n",
    "def check_data_types(predefined_types, imported_data):\n",
    "    \"\"\"\n",
    "    Check data types of imported data against predefined types.\n",
    "    \n",
    "    Parameters:\n",
    "    - predefined_types (dict): A dictionary where keys are column names and values are predefined data types.\n",
    "    - imported_data (DataFrame): The imported data to check.\n",
    "    \n",
    "    Returns:\n",
    "    - mismatches (dict): A dictionary containing columns with data type mismatches and their corresponding types.\n",
    "    \"\"\"\n",
    "    mismatches = {}\n",
    "    \n",
    "    for column, expected_type in predefined_types.items():\n",
    "        imported_type = imported_data[column].dtype\n",
    "        if imported_type != expected_type:\n",
    "            mismatches[column] = {'Imported Type': imported_type, 'Expected Type': expected_type}\n",
    "\n",
    "    if mismatches =={}:        \n",
    "        print ('Data Type is matching')\n",
    "    else :\n",
    "        print ('Data Type is not matching for the following cases:')\n",
    "    \n",
    "    return mismatches\n",
    "\n",
    "###### This function processes a DataFrame to check if specified columns are present. \n",
    "def process_dataframe(column_data, to_check):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "    This function processes a DataFrame to check if specified columns are present. \n",
    "    It prints a message indicating whether all columns are present or lists the columns that are missing.\n",
    "\n",
    "    Parameters:\n",
    "    - column_data (DataFrame): The DataFrame to be processed.\n",
    "    - to_check (list): A list of columns to check for presence in the DataFrame.\n",
    "\n",
    "    Returns:\n",
    "    None\n",
    "\n",
    "    Example:\n",
    "    column_data = pd.DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "    to_check = ['A', 'B', 'C', 'D']\n",
    "    process_dataframe(column_data, to_check)\n",
    "    # Output: ['D'] is not present in dataframe  DataFrame({'A': [1, 2, 3], 'B': [4, 5, 6], 'C': [7, 8, 9]})\n",
    "    \"\"\"\n",
    "    columns = column_data.columns\n",
    "    not_present = column_check(to_check, columns)\n",
    "\n",
    "    if len(not_present) == 0:\n",
    "        print(\"All columns are in the dataframe\")\n",
    "    else:\n",
    "        print(not_present, \"is not present in dataframe\", column_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a901d38-e095-4636-9297-c0ad5225a6d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your Template Data to define column names and data types\n",
    "\n",
    "Cap_temp = pd.read_excel(Capacity_template)\n",
    "BOM1_temp = pd.read_excel(BOM1_template)\n",
    "BOM2_temp = pd.read_excel(BOM2_template)\n",
    "\n",
    "# Create predefined types of dictionary\n",
    "predefined_types_cap = create_predefined_types(Cap_temp)\n",
    "predefined_types_BOM1 = create_predefined_types(BOM1_temp)\n",
    "predefined_types_BOM2 = create_predefined_types(BOM2_temp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b894d77c-209d-4958-bdda-00b3fc3dfadd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Do you want to use default file paths? (Y/N):  y\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table Paths:  BOM1.xlsx BOM2.xlsx Capacity_DD_Filtered.xlsx\n"
     ]
    }
   ],
   "source": [
    "##### Read the Input Files ####\n",
    "BOM1_file,BOM2_file, capacity_file = get_table_paths()\n",
    "print(\"Table Paths: \", BOM1_file,BOM2_file, capacity_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9ad45fc3-b46f-424a-9311-98b876cf18da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Reading .... Done\n",
      "All columns are in the dataframe\n",
      "Data Type is matching\n",
      "All columns are in the dataframe\n",
      "Data Type is matching\n",
      "All columns are in the dataframe\n",
      "Data Type is matching\n",
      " Data Template checking ......Done\n",
      "BOM1 filter is processed Successfully!!\n",
      "BOM2 filter is processed Successfully!!\n",
      "BOM Data filtered Successfully!! The data is created as- BOM Filtered.csv \n"
     ]
    }
   ],
   "source": [
    "######################  Execute the Data Processing #########################\n",
    "\n",
    "'''\n",
    "Step - 1 : BOM Filter - Map BOM Data against Capacity-DD Mapping file and then filter for available cases, \n",
    "for the rest put retain flag as 0 \n",
    "\n",
    "Step - 2 : Tag BOM Version to the data and combine the filtered BOM into one Data table\n",
    "\n",
    "'''\n",
    "\n",
    "try:\n",
    "    \n",
    "    #### Read the Tables \n",
    "    BOM1_file = pd.read_excel(BOM1_file)\n",
    "    BOM2_file = pd.read_excel(BOM2_file)\n",
    "    Capacity_file = pd.read_excel(capacity_file)\n",
    "\n",
    "    print(\"Data Reading .... Done\")\n",
    "    \n",
    "    ### Check data types and templates ####\n",
    "    ### If all of these passes, then let it go to the next step####\n",
    "\n",
    "    ## Check BOM1 data template\n",
    "    process_dataframe(BOM1_file, BOM1_temp.columns)\n",
    "    check_data_types(predefined_types_BOM1,BOM1_file)\n",
    "\n",
    "    ## Check BOM2 data template\n",
    "    process_dataframe(BOM2_file, BOM2_temp.columns)\n",
    "    check_data_types(predefined_types_BOM2,BOM2_file)\n",
    "\n",
    "\n",
    "    ## Check capacity data template\n",
    "    process_dataframe(Capacity_file, Cap_temp.columns)\n",
    "    check_data_types(predefined_types_cap,Capacity_file)\n",
    "\n",
    "    print(\" Data Template checking ......Done\")\n",
    "\n",
    "    #Take Capacity Base for only those where retain_flag =1\n",
    "    BOM_base = Capacity_file[Capacity_file['retain_flag']==1]\n",
    "\n",
    "    #### We need only FG+Factory mapping to pull BOM against it ####\n",
    "\n",
    "    # Select only 'FG Code' and 'Factory' columns\n",
    "    BOM_base1 = BOM_base[['FG Code', 'Factory']]\n",
    "\n",
    "    # Drop duplicate rows based on 'FG Code' and 'Factory' columns\n",
    "    BOM_base1 = BOM_base1.drop_duplicates()\n",
    "\n",
    "    ### Add Factory Mapping to Flatten BOM data\n",
    "\n",
    "    # BOM1_file['FactCode'] = BOM1_file.apply(assign_factcode, axis=1)\n",
    "    # BOM2_file['FactCode'] = BOM2_file.apply(assign_factcode, axis=1)\n",
    "\n",
    "    # Check BOM-1 availability based on DD-Capacity mapping \n",
    "    Filter_BOM1 = pd.merge(BOM_base1 ,BOM1_file,left_on=['Factory','FG Code'], \n",
    "                                    right_on=['FactCode','ASSEMB_ITEM_CODE'], \n",
    "                                    how='left')\n",
    "\n",
    "    Filter_BOM1['retain_flag_BOM'] = 1  # Default value is 1\n",
    "    Filter_BOM1['blank_flag_BOM'] = 0  # Default value is 0\n",
    "    # Filter_BOM1.loc[(Filter_BOM1['COMP_QTY'].isnull()) | (Filter_BOM1['COMP_QTY'] == 0), 'retain_flag_BOM'] = 0\n",
    "    # Updating retain flag for only blank cases and including zeros.\n",
    "    Filter_BOM1.loc[(Filter_BOM1['COMP_QTY'].isnull()), 'retain_flag_BOM'] = 0\n",
    "    Filter_BOM1.loc[(Filter_BOM1['COMP_QTY'] == 0), 'blank_flag_BOM'] = 1\n",
    "\n",
    "    BOM1 = Filter_BOM1[['Factory','FG Code', 'ASSEMB_ITEM_DESC',\n",
    "       'ASSEMB_UOM', 'COMP_ITEM_CODE','COMP_DESC','COMP_UOM','COMP_QTY','Packing flag','retain_flag_BOM']]\n",
    "    \n",
    "    if BOM1[BOM1['retain_flag_BOM'] == 1 ].empty:\n",
    "        \n",
    "        print ('No common records found in Demand-Capability Mapping and BOM1, please check the source data')\n",
    "    else:\n",
    "        print ('BOM1 filter is processed Successfully!!')\n",
    "\n",
    "    # Check BOM-2 availability based on DD-Capacity mapping \n",
    "\n",
    "    # Check BOM2 availability, taken only the common cases here \n",
    "\n",
    "    Filter_BOM2 = pd.merge(BOM_base1,BOM2_file,left_on=['Factory','FG Code'], \n",
    "                                    right_on=['FactCode','ASSEMB_ITEM_CODE'], \n",
    "                                    how='inner')\n",
    "\n",
    "    Filter_BOM2['retain_flag_BOM'] = 1  # Default value is 1\n",
    "    Filter_BOM2['blank_flag_BOM'] = 0  # Default value is 0\n",
    "    # Filter_BOM2.loc[(Filter_BOM2['COMP_QTY'].isnull()) | (Filter_BOM2['COMP_QTY'] == 0), 'retain_flag_BOM'] = 0\n",
    "     # Updating retain flag for only blank cases and including zeros.\n",
    "    Filter_BOM2.loc[(Filter_BOM2['COMP_QTY'].isnull()), 'retain_flag_BOM'] = 0\n",
    "    Filter_BOM2.loc[(Filter_BOM1['COMP_QTY'] == 0), 'blank_flag_BOM'] = 1\n",
    "\n",
    "    BOM2 = Filter_BOM2[['Factory','FG Code', 'ASSEMB_ITEM_DESC',\n",
    "       'ASSEMB_UOM', 'COMP_ITEM_CODE','COMP_DESC','COMP_UOM','COMP_QTY','Packing flag','retain_flag_BOM']]\n",
    "    \n",
    "    if BOM2[BOM2['retain_flag_BOM'] == 1 ].empty:\n",
    "        \n",
    "        print ('No common records found in Demand-Capability Mapping and BOM2, please check the source data')\n",
    "    else:\n",
    "        print ('BOM2 filter is processed Successfully!!')\n",
    "\n",
    "    ### Combine the BOM into one dataset\n",
    "    BOM1['BOM_version'] = \"BOM-1\"\n",
    "    BOM2['BOM_version'] = \"BOM-2\"\n",
    "\n",
    "    ###BOM Filtered\n",
    "    BOM_filtered = pd.concat([BOM1,BOM2], ignore_index=True)\n",
    "    if len(BOM_filtered)>0 :\n",
    "        # Check for duplicate rows based on specified columns\n",
    "        duplicate_rows = BOM_filtered.duplicated(subset=['BOM_version', 'Factory', 'FG Code', 'COMP_ITEM_CODE'], keep='first')\n",
    "        \n",
    "        # Filter out duplicate rows, keeping only the first observation\n",
    "        unique_BOM_filtered = BOM_filtered[~duplicate_rows]\n",
    "        \n",
    "        # Display the resulting DataFrame\n",
    "        unique_BOM_filtered.to_csv('BOM Filtered.csv',index=False),\n",
    "        print ('BOM Data filtered Successfully!! The data is created as- BOM Filtered.csv ')\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "       print (\"Data Processing stopped for DD-Capacity and BOM Mapping due to the following error: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daecab3e-f399-4038-80ae-ceefd6d3d716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Con_rate', 'ORGANIZATION_CODE', 'PERIOD_CODE', 'ITEM_CODE',\n",
       "       'DESCRIPTION', 'CMPNT_COST', 'Consumption cost ($USD)'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cons_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "19330dd3-21f8-42c4-a7ab-9ec37e21e828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ######################  Execute the Data Processing #########################\n",
    "# '''\n",
    "# Step - 3: Derive Only Retained BOM Data\n",
    "# Step - 4: Prepare a List of RMs that are being used in the retained BOM data\n",
    "# Step - 5: Map Key Item's RM Cost, and other RM Costs\n",
    "# Step - 6: QC For RM costs\n",
    "\n",
    "# '''\n",
    "\n",
    "# try:\n",
    "#     ############################## Prep base RM List ##################################################\n",
    "\n",
    "#     BOM_retained = pd.concat([BOM1[BOM1['retain_flag_BOM']==1],BOM2[BOM2['retain_flag_BOM']==1]], ignore_index=True)\n",
    "#     # Selecting only the required columns\n",
    "#     RM_Used = BOM_retained[['Factory', 'COMP_ITEM_CODE']]\n",
    "#     # Dropping duplicates\n",
    "#     RM_Used = RM_Used.drop_duplicates()\n",
    "#     if len(RM_Used)>0:\n",
    "#           print ('RM List prepared Successfully!!')\n",
    "#     else:\n",
    "#           print ('RM list is not prepared properly. Please check the input data')\n",
    "    \n",
    "#     RM_list = RM_Used\n",
    "#     RM_list['temp'] = 1\n",
    "\n",
    "#     ########### List of months -- Since we want to map the RM cost data for all the months ###########\n",
    "#     data = {'MthNum': range(1, 13)}  # Generates numbers from 1 to 12\n",
    "#     MthNum = pd.DataFrame(data)\n",
    "#     MthNum['temp']=1\n",
    "\n",
    "#     # Perform a full outer join on the 'temp' column\n",
    "#     RM_Base = pd.merge(RM_list, MthNum, on='temp', how='outer').drop(columns=['temp'])\n",
    "#     RM_Base.head()\n",
    "\n",
    "#     #Check for counts\n",
    "#     #### Need to add error handling properly#####################\n",
    "   \n",
    "\n",
    "#     if len(RM_Base) != len(RM_list)*len(MthNum):\n",
    "#         print(\"Count mismatch error at Facotry-RM-Month level: Stopping the process...\")\n",
    "        \n",
    "#     else:            \n",
    "#         print ('Factory-RM-Month Base list .....Done')\n",
    "\n",
    "#     '''\n",
    "\n",
    "#     RM-PM Cost Logic to be used :\n",
    "\n",
    "#     1. For key commodities-\n",
    "#         a) for first 3 months, the consumption price will be applied\n",
    "#         b) for rest of the 10 months, the forcasted price will be applied \n",
    "#     2. For other RMs for all the months forcasted price to be taken\n",
    "#     3. For all the cases, where ever both the costs are missing we have to use budgeted cost\n",
    "\n",
    "#     '''\n",
    "#     ###################### Cost Mapping For Key Commodities #####################################\n",
    "\n",
    "#     ## Filter Data based on Key commodities\n",
    "\n",
    "#     # List of entities from key_commodities DataFrame\n",
    "#     key_entities = key_commodities['RM_Code'].tolist()\n",
    "\n",
    "#     # Filtering data based on the key commodities\n",
    "#     filter_key = RM_Base[RM_Base['COMP_ITEM_CODE'].isin(key_entities)]\n",
    "#     filter_key.rename(columns={'Factory': 'FACTCode'}, inplace=True)\n",
    "#     print (\" The following RMs has been considered as Key Commodity, to add more please update the Key Commodity Master list\", filter_key['COMP_ITEM_CODE'].unique())\n",
    "\n",
    "#     ##### Define Forecast cost data\n",
    "#     frcst_cost = df_frct_final.copy()\n",
    "\n",
    "#     ##### Define Item Cost data\n",
    "#     item_cost = cons_df.copy()\n",
    "\n",
    "#     ### Define  Budgeted cost\n",
    "#     bud_cost = bud_df_final1.copy()\n",
    "     \n",
    "    \n",
    "#     # Merge with item_cost DataFrame for the first 3 months\n",
    "\n",
    "#     # merged_first_3_months = pd.merge(filter_key[filter_key['MthNum'].isin([1,2,3])], item_cost, \n",
    "#     #                                 left_on=['FACTCode', 'COMP_ITEM_CODE'], \n",
    "#     #                                 right_on=['ORGANIZATION_CODE', 'ITEM_CODE'], \n",
    "#     #                                 how='left')\n",
    "\n",
    "#     # print('Consumption Cost is mapped')\n",
    "#     ############ Map Forecasted cost for key commodities as Consumption cost is missing\n",
    "\n",
    "#     merged_first_3_months = pd.merge(filter_key[filter_key['MthNum'].isin([1,2,3])], frcst_cost, \n",
    "#                                     left_on=['FACTCode', 'COMP_ITEM_CODE', 'MthNum'], \n",
    "#                                     right_on=['Factory code', 'Code', 'Month1'], \n",
    "#                                     how='left')\n",
    "\n",
    "#     print('Consumption Cost is mapped')\n",
    "    \n",
    "\n",
    "#     # Merge with frcst_cost DataFrame for the remaining months\n",
    "#     merged_remaining_months = pd.merge(filter_key[~filter_key['MthNum'].isin([1,2,3])], frcst_cost, \n",
    "#                                     left_on=['FACTCode', 'COMP_ITEM_CODE', 'MthNum'], \n",
    "#                                     right_on=['Factory code', 'Code', 'Month1'], \n",
    "#                                     how='left')\n",
    "    \n",
    "#     if len(merged_remaining_months[merged_remaining_months['Value-TON revised']>0])>0: \n",
    "#          print ('Forecasted cost mapped for key commodities')\n",
    "#     else:\n",
    "#          print('Forecasted cost is not available for Key commodities')\n",
    "\n",
    "#     # Key_three_months= merged_first_3_months[['FACTCode', 'COMP_ITEM_CODE', 'MthNum','Consumption cost ($USD)']]\n",
    "#     # # Renaming columns\n",
    "#     # Key_three_months = Key_three_months.rename(columns={\n",
    "#     #     'Consumption cost ($USD)': 'RM Cost'\n",
    "#     # })\n",
    "#     Key_three_months = merged_first_3_months[['FACTCode', 'COMP_ITEM_CODE', 'MthNum','Value-TON revised']]\n",
    "#     Key_remaining_months = merged_remaining_months[['FACTCode', 'COMP_ITEM_CODE', 'MthNum','Value-TON revised']]\n",
    "#     # Renaming columns\n",
    "#     Key_remaining_months = Key_remaining_months.rename(columns={\n",
    "#         'Value-TON revised': 'RM Cost'\n",
    "#     })\n",
    "#     # Renaming columns\n",
    "#     Key_three_months = Key_remaining_months.rename(columns={\n",
    "#         'Value-TON revised': 'RM Cost'\n",
    "#     })\n",
    "#     key_cost = pd.concat([Key_three_months, Key_remaining_months], ignore_index=True)\n",
    "#     # key_cost  \n",
    "#     # Set 'retain_flag' column to 1 where 'RM Cost' is greater than 0\n",
    "#     key_cost.loc[key_cost['RM Cost'] > 0, 'retain_flag'] = 1\n",
    "\n",
    "#     ###################### Cost Mapping For Other RM and PMs #####################################\n",
    "\n",
    "#     # Filtering data based on Non-Key Commodities\n",
    "#     filter_rest = RM_Base[~RM_Base['COMP_ITEM_CODE'].isin(key_entities)]\n",
    "#     filter_rest['COMP_ITEM_CODE'].unique() \n",
    "#     filter_rest.rename(columns={'Factory': 'FACTCode'}, inplace=True)\n",
    "\n",
    "#     # Merge with frcst_cost DataFrame for the remaining months\n",
    "#     filter_rest_cost = pd.merge(filter_rest, frcst_cost, \n",
    "#                                     left_on=['FACTCode', 'COMP_ITEM_CODE', 'MthNum'], \n",
    "#                                     right_on=['Factory code', 'Code', 'Month1'], \n",
    "#                                     how='left')\n",
    "#     if len(filter_rest_cost[filter_rest_cost['Value-TON revised']>=0])>0:\n",
    "        \n",
    "#         print(\"Forcasted Cost is mapped for non Key commodities\")\n",
    "\n",
    "#     else:\n",
    "         \n",
    "#         print (\"Forcasted cost unavilable please check the input data\")\n",
    "\n",
    "#     ##### Rename The columns #######\n",
    "        \n",
    "#     filter_rest_cost = filter_rest_cost[['FACTCode', 'COMP_ITEM_CODE', 'MthNum','Value-TON revised']]\n",
    "#     # Renaming columns\n",
    "#     filter_rest_cost = filter_rest_cost.rename(columns={\n",
    "#         'Value-TON revised': 'RM Cost'\n",
    "#     })\n",
    "#     # filter_rest_cost\n",
    "\n",
    "#     ####################  Get Unmapped parts from each dataset #############################################\n",
    "\n",
    "#     ## If there is blank or zero after mapping with consumption cost and forcasted cost, will be taken as unmapped and will be mapped against Budgeted Numbers\n",
    "\n",
    "#     # key_cost_unmapped = key_cost[(key_cost['RM Cost'] <= 0) | (key_cost['RM Cost'].isnull())]\n",
    "#     # key_cost_mapped = key_cost[(key_cost['RM Cost']>0)]\n",
    "#     # key_cost['retain flag'] = 1\n",
    "\n",
    "#     # key_cost_unmapped.head()\n",
    "\n",
    "\n",
    "#     filter_rest_cost_unmapped = filter_rest_cost[(filter_rest_cost['RM Cost'] <= 0) | (filter_rest_cost['RM Cost'].isnull())]\n",
    "#     filter_rest_cost_mapped = filter_rest_cost[(filter_rest_cost['RM Cost'] > 0)]\n",
    "#     filter_rest_cost_mapped['retain flag'] = 1\n",
    "\n",
    "\n",
    "#     # filter_rest_cost_unmapped\n",
    "\n",
    "#     ## Check the counts after splitting\n",
    "#     ######### Need to add effor handling properly ###############\n",
    "             \n",
    "#     if (len(filter_rest_cost)==len(filter_rest_cost_unmapped)+len(filter_rest_cost_mapped)):\n",
    "        \n",
    "#         print(\"Unmapped cases splitting sucessful !!\")\n",
    "    \n",
    "#     else :\n",
    "            \n",
    "#          print (\"Count Mismatch after splitting - Error\")\n",
    "\n",
    "   \n",
    "\n",
    "#     # ###Map the unmapped cases with the budgeted cost\n",
    "#     # key_cost_unmapped_bud = pd.merge(key_cost_unmapped [['FACTCode', 'COMP_ITEM_CODE', 'MthNum']], bud_cost, \n",
    "#     #                                 left_on=['FACTCode', 'COMP_ITEM_CODE', 'MthNum'], \n",
    "#     #                                 right_on=['FactCode', 'Ingredient Item', 'MthNum'], \n",
    "#     #                                 how='left')\n",
    "#     # key_cost_unmapped_bud = key_cost_unmapped_bud[['FACTCode', 'COMP_ITEM_CODE', 'MthNum','Bud_Cost_USD']]\n",
    "#     # key_cost_unmapped_bud['retain flag'] = 0 # Set default value to 0\n",
    "#     # key_cost_unmapped_bud.loc[(key_cost_unmapped_bud['Bud_Cost_USD'].notnull())& (key_cost_unmapped_bud['Bud_Cost_USD'] != 0), 'retain flag'] = 1\n",
    "#     # # Renaming columns\n",
    "#     # key_cost_unmapped_bud = key_cost_unmapped_bud.rename(columns={\n",
    "#     #     'Bud_Cost_USD': 'RM Cost'\n",
    "#     # })\n",
    "#     # # key_cost_unmapped_bud       \n",
    "\n",
    "#     ##RM Cost for rest things\n",
    "\n",
    "#     filter_rest_cost_unmapped_bud = pd.merge(filter_rest_cost_unmapped [['FACTCode', 'COMP_ITEM_CODE', 'MthNum']], bud_cost, \n",
    "#                                     left_on=['FACTCode', 'COMP_ITEM_CODE', 'MthNum'], \n",
    "#                                     right_on=['FactCode', 'Ingredient Item', 'MthNum'], \n",
    "#                                     how='left')\n",
    "#     filter_rest_cost_unmapped_bud = filter_rest_cost_unmapped_bud[['FACTCode', 'COMP_ITEM_CODE', 'MthNum','Bud_Cost_USD']]\n",
    "#     filter_rest_cost_unmapped_bud['retain flag'] = 0  # Set default value to 0\n",
    "#     filter_rest_cost_unmapped_bud.loc[(filter_rest_cost_unmapped_bud['Bud_Cost_USD'].notnull())&(filter_rest_cost_unmapped_bud['Bud_Cost_USD']!=0), 'retain flag'] = 1\n",
    "#     # Renaming columns\n",
    "#     filter_rest_cost_unmapped_bud = filter_rest_cost_unmapped_bud.rename(columns={\n",
    "#         'Bud_Cost_USD': 'RM Cost'\n",
    "#     })\n",
    "#     # filter_rest_cost_unmapped_bud\n",
    "\n",
    "#     # Combine all the RM cost into one table \n",
    "#     RM_Cost_mapped_old = pd.concat([key_cost,filter_rest_cost_mapped,filter_rest_cost_unmapped_bud], ignore_index=True)\n",
    "    \n",
    "#     RM_Cost_mapped_old.to_csv(r'RM_Cost_mapped_old.csv', index=False)      \n",
    "\n",
    "\n",
    "# except Exception as e:\n",
    "\n",
    "#        print (\"RM Cost mapping process failed due to the following error: \", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e083141e-33d2-48ba-8a26-2a36a4093f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RM List prepared Successfully!!\n",
      "Factory-RM-Month Base list .....Done\n"
     ]
    }
   ],
   "source": [
    "######################  Execute the Data Processing #########################\n",
    "'''\n",
    "Step - 3: Derive Only Retained BOM Data\n",
    "Step - 4: Prepare a List of RMs that are being used in the retained BOM data\n",
    "Step - 5: Map Key Item's RM Cost, and other RM Costs\n",
    "Step - 6: QC For RM costs\n",
    "\n",
    "'''\n",
    "\n",
    "try:\n",
    "    ################################### RM Cost Old derivation ####################################\n",
    "    BOM_retained = pd.concat([BOM1[BOM1['retain_flag_BOM']==1],BOM2[BOM2['retain_flag_BOM']==1]], ignore_index=True)\n",
    "    # Selecting only the required columns\n",
    "    RM_Used = BOM_retained[['Factory', 'COMP_ITEM_CODE']]\n",
    "    # Dropping duplicates\n",
    "    RM_Used = RM_Used.drop_duplicates()\n",
    "    if len(RM_Used)>0:\n",
    "        print ('RM List prepared Successfully!!')\n",
    "    else:\n",
    "        print ('RM list is not prepared properly. Please check the input data')\n",
    "\n",
    "    RM_list = RM_Used\n",
    "    RM_list['temp'] = 1\n",
    "\n",
    "    ########### List of months -- Since we want to map the RM cost data for all the months ###########\n",
    "    data = {'MthNum': range(1, 13)}  # Generates numbers from 1 to 12\n",
    "    MthNum = pd.DataFrame(data)\n",
    "    MthNum['temp']=1\n",
    "\n",
    "    # Perform a full outer join on the 'temp' column\n",
    "    RM_Base = pd.merge(RM_list, MthNum, on='temp', how='outer').drop(columns=['temp'])\n",
    "    RM_Base.head()\n",
    "\n",
    "    #Check for counts\n",
    "    #### Need to add error handling properly#####################\n",
    "\n",
    "\n",
    "    if len(RM_Base) != len(RM_list)*len(MthNum):\n",
    "        print(\"Count mismatch error at Facotry-RM-Month level: Stopping the process...\")\n",
    "        \n",
    "    else:            \n",
    "        print ('Factory-RM-Month Base list .....Done')\n",
    "\n",
    "\n",
    "    '''\n",
    "\n",
    "    RM-PM Cost Logic to be used :\n",
    "\n",
    "    For all the RMs only forcasted price will be mapped\n",
    "\n",
    "    '''\n",
    "    ##### Define Forecast cost data\n",
    "    frcst_cost = df_frct_final.copy()\n",
    "    mapped_cost =  pd.merge(RM_Base, frcst_cost, \n",
    "                                    left_on=['Factory', 'COMP_ITEM_CODE', 'MthNum'], \n",
    "                                    right_on=['Factory code', 'Code', 'Month1'], \n",
    "                                    how='left')\n",
    "    mapped_cost['retain_flag']=0\n",
    "    # Set 'retain_flag' column to 1 where 'RM Cost' is greater than 0\n",
    "    mapped_cost.loc[mapped_cost['Value-TON revised'] > 0, 'retain_flag'] = 1\n",
    "    # mapped_cost.columns\n",
    "    mapped_cost = mapped_cost[['Factory', 'COMP_ITEM_CODE', 'MthNum','Value','retain_flag']]\n",
    "    mapped_cost = mapped_cost.rename(columns={\n",
    "        'Factory': 'FACTCode',\n",
    "        'COMP_ITEM_CODE': 'COMP_ITEM_CODE',\n",
    "        'MthNum': 'MthNum',\n",
    "        'Value': 'RM Cost',\n",
    "        'retain_flag': 'retain_flag'\n",
    "    })\n",
    "    mapped_cost\n",
    "    mapped_cost.to_csv(r'RM_Cost_mapped_old.csv', index=False)  \n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "    print (\"RM Cost mapping process failed due to the following error: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2420891a-64a3-4f61-921e-e4b4071110a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Monthly RM cost is prepared and generated !!!! QC pending .......\n",
      "RMs where the check is not applied:\n",
      "MultiIndex([], names=['FACTCode', 'COMP_ITEM_CODE'])\n",
      "RM landed cost varies more than 5% month-on-month for RMs added in the report at: QC_failed.csv\n"
     ]
    }
   ],
   "source": [
    "####################### Adding Back missing Cost ##########################################################\n",
    "try:\n",
    "\n",
    "    ##### New RM costs are added in 'Average RM Cost New' . it contains old data  and new data from missing file\n",
    "        \n",
    "    RM_Cost_mapped= pd.read_csv(r'RM_Cost_mapped_old+missing.csv')\n",
    "    \n",
    "    \n",
    "    #####################################################################\n",
    "    print (\" Monthly RM cost is prepared and generated !!!! QC pending .......\")  \n",
    "\n",
    "    '''\n",
    "    QC Check : RM landed cost does not vary more than 5% month-on-month for any RM\n",
    "\n",
    "    Note: The QC will only be applied for the RM-Factory Combinations that has landed cost available for all the months - IF QC is failed a report will be generated for failed cases\n",
    "\n",
    "    '''   \n",
    "\n",
    "    # Filter rows where retain flag is equal to 1\n",
    "    filtered_RM_Cost_mapped = RM_Cost_mapped[RM_Cost_mapped['retain flag'] == 1]\n",
    "\n",
    "    # Group by FACTCode and COMP_ITEM_CODE, and count the number of unique MthNum values\n",
    "    grouped_counts = filtered_RM_Cost_mapped.groupby(['FACTCode', 'COMP_ITEM_CODE'])['MthNum'].nunique()\n",
    "\n",
    "    # Filter groups where the count of unique MthNum values is 12 (for all 12 months)\n",
    "    valid_groups = grouped_counts[grouped_counts == 12].index\n",
    "\n",
    "    # Apply the check for RM landed cost variation for the valid groups\n",
    "    violations = []\n",
    "\n",
    "    # Define column names\n",
    "    columns = ['FACTCode', 'COMP_ITEM_CODE', 'MthNum', 'RM Cost', 'retain flag', 'RM Cost Change']\n",
    "    ## Define Blank Dataframe for QC failed cases \n",
    "    QC_failed = pd.DataFrame(columns=columns)\n",
    "\n",
    "    for fact_code, comp_item_code in valid_groups:\n",
    "        group_data = filtered_RM_Cost_mapped[(filtered_RM_Cost_mapped['FACTCode'] == fact_code) & (filtered_RM_Cost_mapped['COMP_ITEM_CODE'] == comp_item_code)]\n",
    "        group_data['RM Cost Change'] = group_data['RM Cost'].pct_change() * 100\n",
    "        # Set percentage change as zero for the first month\n",
    "        group_data.loc[group_data['MthNum'] == group_data['MthNum'].min(), 'RM Cost Change'] = 0\n",
    "        if group_data['RM Cost Change'].abs().max() > 5:\n",
    "            violations.append((fact_code, comp_item_code))\n",
    "            QC_failed = QC_failed._append(group_data,ignore_index=True)\n",
    "\n",
    "    ### Export a report of RMs that is failing this perticular QC \n",
    "\n",
    "    QC_report_path = 'QC_failed.csv'\n",
    "    QC_failed.to_csv(QC_report_path,index=False)\n",
    "\n",
    "    # List down COMP_ITEM_CODE values for which the check is not applied\n",
    "    not_applied = grouped_counts[grouped_counts < 12].index\n",
    "\n",
    "    print(\"RMs where the check is not applied:\")\n",
    "    print(not_applied)\n",
    "\n",
    "    if violations:\n",
    "        print(\"RM landed cost varies more than 5% month-on-month for RMs added in the report at:\",QC_report_path )\n",
    "        \n",
    "    else:\n",
    "        print(\"RM landed cost does not vary more than 5% month-on-month for any RM.\")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "       print (\"RM Cost mapping process failed due to the following error: \", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "16896a29-4337-4cec-8ec5-29672e1aa943",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filtered_RM_Cost_mapped is ready\n",
      "No duplicate entries found for 'FACTCode' and 'COMP_ITEM_CODE' combinations.\n",
      "Average RM Cost derivation is Done!!! \n"
     ]
    }
   ],
   "source": [
    "######################  Execute the Data Processing #########################\n",
    "'''\n",
    "Step-7: Derive Average RM cost for only those cases where Factory-RM level cost is available for all the months and return the average cost data\n",
    "\n",
    "'''\n",
    "\n",
    "try:\n",
    "       \n",
    "    #### Take sum of retain flag ###\n",
    "    df2 = RM_Cost_mapped.groupby(['FACTCode', 'COMP_ITEM_CODE'])['retain flag'].sum()\n",
    "    df2 = pd.DataFrame(df2)\n",
    "\n",
    "    # Merge RM_Cost_mapped with df2 based on 'FACTCode' and 'COMP_ITEM_CODE'\n",
    "    merged_df = pd.merge(RM_Cost_mapped, df2, on=['FACTCode', 'COMP_ITEM_CODE'], suffixes=('_RM_Cost_mapped', '_df2'))\n",
    "\n",
    "    # Filter merged_df for rows where retain flag is 12 (As there are total of 12 months)\n",
    "    filtered_RM_Cost_mapped = merged_df[merged_df['retain flag_df2'] == 12]\n",
    "    filtered_RM_Cost_mapped\n",
    "    print('filtered_RM_Cost_mapped is ready')\n",
    "    \n",
    "    # Group by 'FACTCode' and 'COMP_ITEM_CODE' and calculate the mean of 'RM Cost' within each group\n",
    "    average_RM_cost = filtered_RM_Cost_mapped.groupby(['FACTCode', 'COMP_ITEM_CODE'])['RM Cost'].mean().reset_index()\n",
    "    average_RM_cost['retain_flag'] = 12\n",
    "    # average_RM_cost\n",
    "\n",
    "    # Display the resulting DataFrame\n",
    "    average_RM_cost1 = average_RM_cost.copy()\n",
    "    # df.groupby(['col1', 'col2']).size().reset_index(name='counts')\n",
    "    average_RM_cost1 = average_RM_cost1.groupby(['FACTCode', 'COMP_ITEM_CODE']).size().reset_index(name='counts')\n",
    "    if len(average_RM_cost1[average_RM_cost1['counts']>1])== 0:\n",
    "          print(\"No duplicate entries found for 'FACTCode' and 'COMP_ITEM_CODE' combinations.\")\n",
    "          average_RM_cost.to_csv('Average RM Cost.csv',index=False)\n",
    "          print( \"Average RM Cost derivation is Done!!! \")\n",
    "    else:\n",
    "        duplicate_entries = average_RM_cost1[average_RM_cost1['counts']>1]\n",
    "        print(\"Duplicate entries found for the following 'FACTCode' and 'COMP_ITEM_CODE' combinations: (please check the input data)\")\n",
    "        print(duplicate_entries[['FACTCode', 'COMP_ITEM_CODE']].drop_duplicates())\n",
    "        print( \"Average RM Cost derivation is Stopped..... \")\n",
    "\n",
    "\n",
    "except Exception as e:\n",
    "\n",
    "       print (\"RM Cost mapping process failed due to the following error: \", e)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10afbf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
